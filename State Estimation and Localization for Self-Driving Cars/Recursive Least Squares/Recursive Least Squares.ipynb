{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "----\n",
    "Given your experience with batch least squares (where all measurements are processed at once), you now decide convert your batch solution to a recursive one for added flexibility. Recall that you have the following data:\n",
    "\n",
    "| Current (A) | Voltage (V) |\n",
    "|-------------|-------------|\n",
    "| 0.2         | 1.23        |\n",
    "| 0.3         | 1.38        |\n",
    "| 0.4         | 2.06        |\n",
    "| 0.5         | 2.47        |\n",
    "| 0.6         | 3.17        |\n",
    "\n",
    "This time, you intend to fit a linear model that includes an offset term, $V = RI + b$. If Ohm's law ($V = RI$) holds, you expect this offset to be very near to zero.\n",
    "\n",
    "To use the recursive least squares formulation, you must have a prior estimate of the resistance and its associated uncertainty (otherwise, you won't know how to weigh the information you receive from a new measurement). You choose to set the initial parameters under the assumption that your prior estimate of the resistance, $R = 4$, is not very good. Also, since you are fairly sure that Ohm's law ($V = RI$) does, in fact, hold, you feel that it is safe to assume with high confidence that the offset term $b$ is close to zero. After some thought, you choose to intialize the recursive estimator as follows:\n",
    "\n",
    "$$\\hat{R} \\sim \\mathcal{N}(4, 9.0),~~\\hat{b} \\sim \\mathcal{N}(0, 0.2)$$\n",
    "\n",
    "Your initial guess is that $\\hat{R}$ follows a Gaussian or normal distribution (recall that you do not know the exact value of $R$, so it must be considered as a random variable) with a mean of $4~\\Omega$ and a standard deviation of $3~ \\Omega$ (i.e., a variance of $9~\\Omega^{2}$). Similarly, your intial guess is that $\\hat{b}$ should also follow a normal distribution with a mean of $0~V$ and a variance of $0.2~V^{2}$.\n",
    "\n",
    "With the data again in hand, your goals are to: \n",
    "1. Fit a line to the data that includes an offset term (i.e., determine the parameters $R$ and $b$ for $y = Rx + b$) by using the method of recursive least squares. \n",
    "2. Reflect on the differences between the batch and recursive least squares solutions.\n",
    "\n",
    "You may assume that the current values are known exactly, and that the voltage measurements are corrupted by additive, independent and identitically distributed zero-mean Gaussian noise with a standard deviation of $0.15~V$ (i.e., a variance of $0.0225 ~ V^2$). You may also assume that your initial estimates for $\\hat{R}$ and $\\hat{b}$ are uncorelated (i.e., the off-diagonal elements of the $2 \\times 2$ covariance matrix are zero). \n",
    "\n",
    "## Getting Started\n",
    "----\n",
    "As before, the first step is to import the neccesary Python modules and load the current values and voltage measurements into NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I = np.array([[0.2, 0.3, 0.4, 0.5, 0.6]]).T\n",
    "V = np.array([[1.23, 1.38, 2.06, 2.47, 3.17]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(I, V)\n",
    "plt.xlabel('Current (A)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Slope and Offset Parameters\n",
    "----\n",
    "### Batch Estimator\n",
    "Before implementing the recursive least squares estimator, let's examine the parameter estimates given by the batch least squares method used in the previous assignment. This time, you will be fitting a model which contains an offset $y = Rx + b$. This result can be used later for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Batch Solution\n",
    "\n",
    "H = np.ones((5, 2))\n",
    "H[:, 0] = I.ravel()\n",
    "x_ls = inv(H.T.dot(H)).dot(H.T.dot(V))\n",
    "print('The slope and offset parameters of the best-fit line (i.e., the resistance and offset) are [R, b]:')\n",
    "print(x_ls[0, 0])\n",
    "print(x_ls[1, 0])\n",
    "\n",
    "# Plot line.\n",
    "I_line = np.arange(0, 0.8, 0.1).reshape(8, 1)\n",
    "V_line = x_ls[0]*I_line + x_ls[1]\n",
    "\n",
    "plt.scatter(I, V)\n",
    "plt.plot(I_line, V_line)\n",
    "plt.xlabel('Current (A)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the offset parameter $\\hat{b}$ is near zero, while $\\hat{R}$ closely approximates the true resistance value of $R = 5~\\Omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Estimator\n",
    "Now let's try to implement the least squares method recursively! Recall the steps described in Module 1, Lesson 2 - \"Recursive Least Squares\": \n",
    "\n",
    "**Initialize the parameter and covariance estimates**:\n",
    "\n",
    "----\n",
    "$$\n",
    "\\hat{\\mathbf{x}}_0 = E\\left[\\mathbf{x}\\right],\\quad \\mathbf{P}_0 = E\\left[(\\mathbf{x} - \\hat{\\mathbf{x}}_0)(\\mathbf{x} - \\hat{\\mathbf{x}}_0)^T\\right]\n",
    "$$\n",
    "\n",
    "**For every measurement k**:\n",
    "\n",
    "----\n",
    "  * Calculate the gain term: $$\\mathbf{K}_k = \\mathbf{P}_{k-1}\\mathbf{H}_k^T\\left(\\mathbf{H}_k\\mathbf{P}_{k-1}\\mathbf{H}_k^T + \\mathbf{R}_k\\right)^{-1}$$\n",
    "  * Update the parameter estimate: $$\\hat{\\mathbf{x}}_k = \\hat{\\mathbf{x}}_{k-1} + \\mathbf{K}_k\\left(\\mathbf{y}_k - \\mathbf{H}_k\\hat{\\mathbf{x}}_{k-1}\\right)$$\n",
    "  * Update the covariance estimate: $$\\mathbf{P}_k = \\left(\\mathbf{I} - \\mathbf{K}_k\\mathbf{H}_k\\right)\\mathbf{P}_{k-1}$$\n",
    "  \n",
    "In this case, the initial parameter vector $\\hat{\\mathbf{x}}_0$ should contain $\\hat{R}$ and $\\hat{b}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Recursive Solution\n",
    "\n",
    "# Initialize the 2x1 parameter vector x (i.e., x_0).\n",
    "# x_k = ...\n",
    "\n",
    "#Initialize the 2x2 covaraince matrix (i.e. P_0). Off-diangonal elements should be zero.\n",
    "# P_k = ...\n",
    "\n",
    "# Our voltage measurement variance (denoted by R, don't confuse with resistance).\n",
    "R_k = np.array([[0.0225]])\n",
    "\n",
    "# Pre allocate space to save our estimates at every step.\n",
    "num_meas = I.shape[0]\n",
    "x_hist = np.zeros((num_meas + 1, 2))\n",
    "P_hist = np.zeros((num_meas + 1, 2, 2))\n",
    "\n",
    "x_hist[0] = x_k\n",
    "P_hist[0] = P_k\n",
    "\n",
    "# Iterate over all the available measurements.\n",
    "for k in range(num_meas):\n",
    "    # Construct H_k (Jacobian).\n",
    "    # H_k = ...\n",
    "\n",
    "    # Construct K_k (gain matrix).\n",
    "    # K_k = ...\n",
    "                    \n",
    "    # Update our estimate.\n",
    "    # x_k = ...\n",
    " \n",
    "    # Update our uncertainty (covariance)\n",
    "    # P_k = ...    \n",
    "\n",
    "    # Keep track of our history.\n",
    "    P_hist[k + 1] = P_k\n",
    "    x_hist[k + 1] = x_k\n",
    "    \n",
    "print('The slope and offset parameters of the best-fit line (i.e., the resistance and offset) are [R, b]:')\n",
    "print(x_k[0, 0])\n",
    "print(x_k[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results\n",
    "----\n",
    "Let's plot out the solution at each step. Does the resistance value converge towards the batch least squares solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(I, V, label='Data')\n",
    "plt.plot(I_line, V_line, label='Batch Solution')\n",
    "plt.xlabel('Current (A)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.grid(True)\n",
    "\n",
    "I_line = np.arange(0, 0.8, 0.1).reshape(8, 1)\n",
    "\n",
    "for k in range(num_meas):\n",
    "    V_line = x_hist[k, 0]*I_line + x_hist[k, 1]\n",
    "    plt.plot(I_line, V_line, label='Measurement {}'.format(k))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resistance estimate $\\hat{R}$ should approach the true resistance value of $R = 5~\\Omega$ very closely (i.e., to within a few hundredths of ohms). As expected, the offset term $\\hat{b}$ should be small as well (less than 0.1 ohms). Try modifying the initialization (e.g., the intial uncertainty of the prior guess) - can you get a better final esimate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
